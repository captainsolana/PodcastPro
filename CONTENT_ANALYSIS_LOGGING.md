# Content Analysis Models and Enhanced Logging

## ğŸ¤– **Current LLM Models for Content Analysis**

### Research Phase (`/api/ai/research`)
- **Model**: Perplexity `sonar-reasoning`
- **Timeout**: 6 minutes (360,000ms)
- **Max Tokens**: 4,000
- **Purpose**: Comprehensive research with real-time web data

### Content Analysis Phase (`/api/ai/analyze-episodes`) 
- **Model**: OpenAI `gpt-5`
- **Reasoning Effort**: `low` (for faster response)
- **Verbosity**: `medium`
- **Response Format**: `json_object`
- **Purpose**: Episode breakdown and content structuring

## ğŸ“‹ **Enhanced Logging Added**

### Route Level Logging (`server/routes.ts`)

#### Research Route (`/api/ai/research`)
```
ğŸ“Š ROUTE: Starting research phase...
ğŸ“ Research prompt: [first 100 chars]...
ğŸš€ ROUTE: Making research API call...
âœ… ROUTE: Research completed successfully in [X] ms
ğŸ“Š ROUTE: Research sources count: [N]
ğŸ“ˆ ROUTE: Key points extracted: [N]
ğŸ“‹ ROUTE: Statistics found: [N]
```

#### Content Analysis Route (`/api/ai/analyze-episodes`)
```
ğŸ­ ROUTE: Starting content analysis phase...
ğŸ“ Analysis prompt: [first 100 chars]...
ğŸ“Š Research data size: [X] characters
ğŸ§  Using model: GPT-5 with low reasoning effort
ğŸš€ ROUTE: Making content analysis API call...
âœ… ROUTE: Content analysis completed in [X] ms
ğŸ“º ROUTE: Multi-episode result: [true/false]
ğŸ”¢ ROUTE: Total episodes planned: [N]
ğŸ“‹ ROUTE: Episodes breakdown: [N] episodes
```

### Service Level Logging (`server/services/openai.ts`)

#### Research Service
```
ğŸ”¬ SERVICE: Starting research phase
ğŸ“ SERVICE: Research prompt length: [X] characters
ğŸŒ SERVICE: Starting comprehensive research with Perplexity
ğŸ”‘ SERVICE: Perplexity API key status: SET/NOT SET
ğŸ¯ SERVICE: Using Perplexity sonar-reasoning model
âœ… SERVICE: Research completed with rich content for script generation
ğŸ“Š SERVICE: Research content length: [X] characters
ğŸ“ˆ SERVICE: Key points extracted: [N]
ğŸ“‹ SERVICE: Statistics extracted: [N]
```

#### Perplexity API Call
```
ğŸ”¥ SERVICE: ATTEMPTING REAL PERPLEXITY API CALL for research
ğŸ“ SERVICE: Query length: [X] characters
ğŸ¯ SERVICE: Using sonar-reasoning model with 4000 max tokens
ğŸ” SERVICE: Using Perplexity API key: [first8chars]...
ğŸš€ SERVICE: Making REAL Perplexity API call now...
âœ… SERVICE: Perplexity API call completed in [X] ms
ğŸ“Š SERVICE: Perplexity response received, processing...
âœ… SERVICE: Perplexity research content processed, length: [X] characters
ğŸ“ SERVICE: Content preview: [first 200 chars]...
```

#### Content Analysis Service
```
ğŸ­ SERVICE: Starting episode breakdown analysis
ğŸ“ SERVICE: Analysis prompt: [first 100 chars]...
ğŸ§  SERVICE: Using GPT-5 with low reasoning effort
ğŸ“Š SERVICE: Research input size: [X] characters
ğŸš€ SERVICE: Making GPT-5 API call for episode analysis...
âœ… SERVICE: GPT-5 episode analysis completed in [X] ms
ğŸ“º SERVICE: Multi-episode decision: [true/false]
ğŸ”¢ SERVICE: Total episodes planned: [N]
ğŸ“‹ SERVICE: Episode breakdown created: [N] episodes
```

## ğŸ¯ **Benefits of Enhanced Logging**

### 1. **Performance Monitoring**
- **Timing**: Track exact API call durations
- **Bottlenecks**: Identify slow operations
- **Timeouts**: See where timeouts occur

### 2. **Data Flow Tracking**
- **Input Size**: Monitor prompt and data sizes
- **Output Quality**: Track extracted data counts
- **Content Volume**: Monitor research content volume

### 3. **API Status Monitoring**
- **Authentication**: Verify API keys are set
- **Model Usage**: Confirm which models are being used
- **Response Status**: Track successful vs failed calls

### 4. **Debugging Support**
- **Error Context**: Rich error information with timing
- **Data Preview**: See content snippets for debugging
- **Process Flow**: Clear visibility into each processing step

### 5. **Quality Assurance**
- **Research Quality**: Monitor extracted key points and statistics
- **Content Analysis**: Track episode planning decisions
- **Model Performance**: Compare response times and quality

## ğŸš€ **What You'll See in Testing**

When testing the Content Analysis section, you'll now see detailed logs like:

```
ğŸ“Š ROUTE: Starting research phase...
ğŸ“ Research prompt: How UPI transformed digital payments in India...
ğŸŒ SERVICE: Starting comprehensive research with Perplexity
ğŸ¯ SERVICE: Using Perplexity sonar-reasoning model
ğŸš€ SERVICE: Making REAL Perplexity API call now...
âœ… SERVICE: Perplexity API call completed in 45233 ms
ğŸ“Š SERVICE: Research content length: 4247 characters
ğŸ“ˆ SERVICE: Key points extracted: 8
ğŸ“‹ SERVICE: Statistics extracted: 5
âœ… ROUTE: Research completed successfully in 45344 ms

ğŸ­ ROUTE: Starting content analysis phase...
ğŸ§  Using model: GPT-5 with low reasoning effort
ğŸš€ SERVICE: Making GPT-5 API call for episode analysis...
âœ… SERVICE: GPT-5 episode analysis completed in 12445 ms
ğŸ“º SERVICE: Multi-episode decision: true
ğŸ”¢ SERVICE: Total episodes planned: 3
âœ… ROUTE: Content analysis completed in 12556 ms
```

This will help you track exactly what's happening, which models are being used, and how long each step takes! ğŸ“Š
